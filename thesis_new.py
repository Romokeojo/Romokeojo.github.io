# -*- coding: utf-8 -*-
"""Thesis_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9EkXKgtXkSEu8BaoK09gMRJUf1TXtHV
"""

!pip install --upgrade xee
!pip install cartopy
!pip install pymannkendall

import ee
import geemap
ee.Authenticate()
ee.Initialize(project='dolapo')
ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')

import geemap
import xarray as xr
#import xclim
#from xclim.indices import standardized_precipitation_evapotranspiration_index
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import cartopy.crs as ccrs
import cartopy.feature as cfeature
from matplotlib.colors import BoundaryNorm
import pymannkendall as mk
from scipy import stats
from scipy.stats import kendalltau
import statsmodels.api as sm

from google.colab import drive
drive.mount('/content/drive')
output_folder = "/content/drive/MyDrive/Thesis/"

"""The identification of flash droughts in this analysis is based on three primary conditions related to temperature anomalies, evapotranspiration anomalies, and soil moisture percentiles during the growing season.

The approach below follows: [Kingtse et al. 2015 ](https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2015GL064018)

### Conditions for Identifying Flash Droughts

- **Condition (a): Standardized Temperature Anomaly**
  - Calculate the mean (`temperature_climatology`) and standard deviation (`temperature_std`) of temperature for the base period.
  - Compute the standardized temperature anomaly for each pentad
  - The standardized temperature anomaly must be greater than 1 standard deviation.

- **Condition (b): Evapotranspiration (ET) Anomaly**
  - Calculate the mean ET (`et_climatology`) for the base period.
  - Compute the ET anomaly for each pentad
  - The ET anomaly must be greater than 0.

- **Condition (c): Soil Moisture Percentile**
  - Calculate the 40th percentile of soil moisture for the entire growing season period.
  - Soil moisture for each pentad must be less than the 40th percentile.

- **Combined Conditions**
  - A pentad is identified as a flash drought event if all the above conditions (a, b, and c) are satisfied.

Get a country boundary from the GAUL datasets
"""

countries = ee.FeatureCollection('FAO/GAUL/2015/level0')
# get list of countries
country_names = countries.aggregate_array('ADM0_NAME').getInfo()
# Filter the collection to get Tanzania
countries_list = ['Somalia', 'Tanzania', 'Ethiopia', 'Uganda', 'Kenya', 'Eritrea', 'Djibouti', 'Malawi']
eastafrica = countries.filter(ee.Filter.inList('ADM0_NAME', countries_list))

# Get the geometry of Tanzania
roi = eastafrica.geometry()

print(country_names)

"""Small bounding box created for testing

Get ERA 5 Land data variables
"""

climate_vars = ["temperature_2m", "evaporation_from_vegetation_transpiration_sum", "volumetric_soil_water_layer_1"]
start_date = '1980-01-01'
end_date = '2023-12-31'

era5_dataset = (ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')
                .filter(ee.Filter.date(start_date, end_date))
                .filter(ee.Filter.bounds(roi))
                .select(climate_vars))

"""Convert to xarray object"""

#era5_dataset_with_bounds = era5_dataset.map(lambda image: image.set('bounds', image.geometry().bounds()))
ds = xr.open_dataset(era5_dataset, engine='ee',
                         chunks={},
                         crs='EPSG:4326',
                         geometry=roi,
                         scale=0.1)
print(ds)

# quick plot
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
ds['temperature_2m'].isel(time=0).plot(y='lat', ax=ax1)
ds['evaporation_from_vegetation_transpiration_sum'].isel(time=0).plot(y='lat', ax=ax2)

#Aggregate to pentads
ds_pentads = ds.resample(time='5D').mean()

# Define the growing season (September to April)
growing_season = ds_pentads.sel(time=ds_pentads['time.month'].isin([3,4,5,6,7,8]))
#for time_coord in growing_season.isel(time=slice(0, 260)).time:
    #print(time_coord.values)

# Define the base period and filter for the growing season
base_period = growing_season.sel(time=slice('1981-01-01', '2020-12-31'))
#for time_coord in growing_season.isel(time=slice(0, 260)).time:
    #print(time_coord.values)

# Calculate the climatology (mean) and standard deviation for the base period for each pentad
temperature_climatology = base_period['temperature_2m'].mean(dim='time')
temperature_std = base_period['temperature_2m'].std(dim='time')

# Calculate the standardized temperature anomalies for the entire dataset based on pentads
temperature_anomalies = (growing_season['temperature_2m'] - temperature_climatology) / temperature_std

# Calculate the climatology (mean) for ET during the base period for each pentad
et_climatology = base_period['evaporation_from_vegetation_transpiration_sum'].mean(dim='time')

# Calculate the ET anomalies based on the base period
et_anomalies = growing_season['evaporation_from_vegetation_transpiration_sum'] - et_climatology

# Calculate the 40th percentile for soil moisture over the entire growing season period

!pip install bottleneck
# Rank the data along the time dimension
import bottleneck as bn # Import the missing module
# get sm
sm = growing_season['volumetric_soil_water_layer_1'].chunk({'time': -1})
# Rank the data along the time dimension
ranked_eastn = sm.compute().rank(dim='time')
ranked_eastn.to_netcdf(output_folder + 'ranked_eastn.nc')
ranked_eastn = xr.open_dataset(output_folder + 'ranked_east.nc')
# Normalise the ranks to get percentiles
percentiles = (ranked_eastn / ranked_eastn.max(dim='time'))*100
# Add the percentiles back to the dataset
growing_season['soil_moisture_percentiles'] = percentiles

percentiles['volumetric_soil_water_layer_1'].isel(time=0).plot(y='lat')

"""### calculate variables"""

# Condition (a): Standardized Tair anomaly is greater than 1
condition_a = temperature_anomalies > 1

# Condition (b): ET anomaly is greater than 0
# !!! (note here negative values: evaporation should be higher than normal, which would correspond to more negative values of evaporation_from_vegetation_transpiration_sum )
condition_b = et_anomalies > 0

# Condition (c): SM is less than the 40th percentile
condition_c = growing_season['soil_moisture_percentiles']< 40

# Combine conditions to identify pentads that meet all criteria
flash_drought_condition = condition_a & condition_b & condition_c

# Create a new DataArray to store the results
flash_droughts = xr.Dataset({
    'temperature_anomalies': temperature_anomalies,
    'et_anomalies': et_anomalies,
    'sm_40th_percentile': condition_c,
    'flash_drought_condition': flash_drought_condition
})

flash_droughts_computed_eastn = flash_droughts.compute()
flash_droughts_computed_eastn.to_netcdf(output_folder + 'flash_droughts_computed_eastn.nc')
flash_droughts_computed_eastn = xr.open_dataset(output_folder + 'flash_droughts_computed_eastn.nc')

"""### calculate FOC of FD"""

# Calculate the total number of pentads (time steps)
total_pentads = flash_droughts_computed_eastn.dims['time']

# Count the occurrences of flash droughts (True values) along the time dimension
flash_drought_count = flash_droughts_computed_eastn['flash_drought_condition'].sum(dim='time')

# Calculate the Frequency of Occurrence (FOC) as a percentage
foc = (flash_drought_count / total_pentads) * 100

# Convert the result to a Dataset for easier handling and visualization
foc_dataset = xr.Dataset({'FOC': foc})

# remove latitude greater than 10
foc_dataset = foc_dataset.where(foc_dataset.lat <= 15, drop=True)

#select flash drought area
foc_dataset_greater1 = foc_dataset.where(foc_dataset>= 1, drop=True)

#calculate area of flash drought events
total_area = (foc_dataset_greater1.notnull() * 123.92).sum()

#select areas with hotspots of foc
foc_dataset_greater6 = foc_dataset.where(foc_dataset>= 6, drop=True)

#calculate area of flash drought hotspots
total_area = (foc_dataset_greater6.notnull() * 123.92).sum()

"""#plot all variables to check"""

# Select the first time slice for plotting (you can adjust this as needed)
time_index = 0

# Create subplots for plotting multiple variables
fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5), subplot_kw={'projection': ccrs.PlateCarree()})

# Plot temperature anomalies
flash_droughts_computed_sosu['temperature_anomalies'].isel(time=time_index).plot(ax=axes[0],y='lat', transform=ccrs.PlateCarree(), cmap='coolwarm')
axes[0].set_title('Temperature Anomalies')

# Plot ET anomalies
flash_droughts_computed_sosu['et_anomalies'].isel(time=time_index).plot(ax=axes[1],y='lat', transform=ccrs.PlateCarree(), cmap='BrBG')
axes[1].set_title('ET Anomalies')

# Plot SM binary mask
flash_droughts_computed_sosu['sm_40th_percentile'].isel(time=time_index).plot(ax=axes[2],y='lat', transform=ccrs.PlateCarree(), add_colorbar=False)
axes[2].set_title('SM Mask (0 or 1)')

# Plot SM binary mask
flash_droughts_computed_sosu['flash_drought_condition'].isel(time=time_index).plot(ax=axes[3],y='lat', transform=ccrs.PlateCarree(), add_colorbar=False)
axes[3].set_title('FD')

# Add country boundaries to all subplots
for ax in axes:
    ax.add_feature(cfeature.BORDERS, linestyle=':')
    ax.add_feature(cfeature.COASTLINE)

# Show the plot
plt.tight_layout()
plt.show()

"""### Plot FOC map"""

import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature
from matplotlib.colors import BoundaryNorm
#foc_dataset = foc_dataset.where(foc_dataset >= 1, drop=True)
# Define the discrete color boundaries, adjusted for the FOC range
bounds = [0, 1, 2, 3, 4, 5, 6, 7]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
foc_dataset['FOC'].plot(
    ax=ax,
    y='lat',
    transform=ccrs.PlateCarree(),
    cmap='jet',
    norm=norm,
    add_colorbar=False  # Disable the automatic colorbar
)

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Frequency of Occurrence (%)', fontsize=16)  # Increase label size
output_file_path = '/content/drive/MyDrive/Thesis/foc_growing_season_east.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

# Define the discrete color boundaries, adjusted for the FOC range
bounds = [0,1, 2,3, 4,5, 6,7]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
foc_dataset['FOC'].plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        norm=norm, cbar_kwargs={'label': 'Frequency of Occurrence (%)', 'boundaries': bounds, 'ticks': bounds})


# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 20, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 20, 'color': 'black'}  # Customize y-axis label style

cbar = ax.figure.colorbar(ax.collections[0])
cbar.ax.tick_params(labelsize=20)  # Adjust tick label size
cbar.ax.set_ylabel('Frequency of Occurrence (%)', fontsize=24) # Increased label size

# Remove any other plt.show() calls from your code

# Show the plot (only once)
plt.show()

"""#Distribution of flash drought across the mean annual temperature and mean annual precipitation"""

climate_vars = ["total_precipitation_sum"]
start_date = '1980-01-01'
end_date = '2023-12-31'

era5_dataset = (ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')
                .filter(ee.Filter.date(start_date, end_date))
                .filter(ee.Filter.bounds(roi))
                .select(climate_vars))
ds_prep = xr.open_dataset(era5_dataset, engine='ee',
                         chunks={},
                         crs='EPSG:4326',
                         geometry=roi,
                         scale=0.1)
print(ds_prep)

#mean annual temperature
mat = ds['temperature_2m'].groupby('time.year').mean()
mmat = mat.mean(dim=['year'])

#mean annual precipitation
prep = ds_prep['total_precipitation_sum'].groupby('time.year').mean()
ppre = prep.mean(dim=['year'])

mmat = mmat.compute()
ppre = ppre.compute()

mmat.to_netcdf(output_folder + 'mmat.nc')
ppre.to_netcdf(output_folder + 'ppre.nc')

soil = ds['volumetric_soil_water_layer_1'].groupby('time.year').mean()
soil = soil.mean(dim=['year'])
soils = soil.compute()
soils.to_netcdf(output_folder + 'soils.nc')

mmat = xr.open_dataset(output_folder + 'mmat.nc')
ppre = xr.open_dataset(output_folder + 'ppre.nc')

mmat_array = mmat['temperature_2m']
ppre_array = ppre['total_precipitation_sum']
foc = foc_dataset['FOC'].where(foc_dataset['FOC'] >= 1, drop=True)

#Flatten the data for plotting
mat_flat = mmat_array.values.flatten()
prep_flat = ppre_array.values.flatten()
foc_flat = foc.values.flatten()

# Create a DataFrame for easier manipulation and plotting
import pandas as pd

data = pd.DataFrame({
    'MAT': mat_flat,
    'PREP': prep_flat,
    'FOC': foc_flat
})

# Filter out invalid data points (e.g., NaN values)
data = data.dropna()

# Plot the distribution of FOC characteristics in the climate space
plt.figure(figsize=(10, 8))
scatter = plt.scatter(data['PREP'], data['MAT'], c=data['FOC'], cmap='viridis', alpha=0.5, vmin=0, vmax=7)
cbar = plt.colorbar(scatter, label='FOC')
cbar.set_ticks([0, 1, 2, 3, 4, 5, 6, 7])  # Set the ticks for the colorbar
cbar.set_ticklabels(['0', '1', '2', '3', '4', '5', '6', '7'])


plt.xlabel('Mean Annual Precipitation (m)', fontsize = 14)

plt.ylabel('Mean Annual Temperature (K)', fontsize = 14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.title('Distribution of FOC Characteristics in Climate Space')
output_file_path = '/content/drive/MyDrive/Thesis/climatic_dist.tif'
#plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

plt.show()

"""### Temperature Distribution across the flash drought area"""

sets = mmat['temperature_2m'].where(foc_dataset['FOC'] >= 1, drop = True)
#selectp.plot()
#bounds = [0,0.01,0.02,0.03, 0.04, 0.05 ]
bounds = [280, 285, 290,295,300,305,310,315,320]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
sets.plot(
    ax=ax,
    y='lat',
    transform=ccrs.PlateCarree(),
    cmap='jet',
    norm=norm,
    add_colorbar=False  # Disable the automatic colorbar
)

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Temperature (K)', fontsize=16)  # Increase label size
# Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/foc_temp.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""### precipitation Distribution across the flash drought area"""

sets = ppre['total_precipitation_sum'].where(foc_dataset['FOC'] >= 1, drop = True)
#selectp.plot()
bounds = [0,0.001, 0.002, 0.003, 0.004,0.005,0.006,0.007,0.008,0.009,0.01,0.02]
#bounds = [280, 285, 290,295,300,305,310,315,320]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
sets.plot(
    ax=ax,
    y='lat',
    transform=ccrs.PlateCarree(),
    cmap='jet',
    norm=norm,
    add_colorbar=False  # Disable the automatic colorbar
)
# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Precipitation (m)', fontsize=16)  # Increase label size
# Set title
#plt.title('Frequency of occurence')
# Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/foc_preci.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""### soil moisture anomaly distribution across the flash drought area"""

growing_season = ds_pentads.sel(time=ds_pentads['time.month'].isin([3,4,5,6,7,8]))

# Define the base period and filter for the growing season
base_period = growing_season.sel(time=slice('1981-01-01', '2020-12-31'))

# Calculate the climatology (mean) and standard deviation for the base period for each pentad
soil_climatology = base_period['volumetric_soil_water_layer_1'].mean(dim='time')
soil_std = base_period['volumetric_soil_water_layer_1'].std(dim='time')
# Calculate the standardized temperature anomalies for the entire dataset based on pentads
soil_anomalies = (growing_season['volumetric_soil_water_layer_1'] - soil_climatology) / soil_std
soil_anomalies = soil_anomalies.compute()
soil_anomalies.to_netcdf(output_folder + 'soil_anomalies.nc')

#calculate annual mean of soil moisture anomaly
soil = soil_anomalies.groupby('time.year').mean()
soils = soil.mean(dim=['year'])
soils.to_netcdf(output_folder + 'soils.nc')
soils = xr.open_dataset(output_folder + 'soils.nc')
soils = soils.where(foc_dataset['FOC'] >= 1, drop = True)

bounds = [-0.2, -0.15, -0.1, -0.05, 0, 0.5, 1, 1.5, 2]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
soils['volumetric_soil_water_layer_1'].plot(
    ax=ax,
    y='lat',
    transform=ccrs.PlateCarree(),
    cmap='jet',
    norm=norm,
    add_colorbar=False  # Disable the automatic colorbar
)

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Standardised Soil Moisture Anomaly', fontsize=16)  # Increase label size
# Set title

#Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/soil_anomaly.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

"""### Radiation anomaly distribution across the flash drought area"""

climate_vars = ["surface_net_solar_radiation_sum"]
start_date = '1980-01-01'
end_date = '2023-12-31'

rad_dataset = (ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')
                .filter(ee.Filter.date(start_date, end_date))
                .filter(ee.Filter.bounds(roi))
                .select(climate_vars))
ds_rad = xr.open_dataset(rad_dataset, engine='ee',
                         chunks={},
                         crs='EPSG:4326',
                         geometry=roi,
                         scale=0.1)
print(ds_rad)
ds_rad["surface_net_solar_radiation_sum"].isel(time=0).plot(y='lat')
ds_rad_pentads = ds_rad.resample(time='5D').mean()


growing_season_rad= ds_rad_pentads.sel(time=ds_rad_pentads['time.month'].isin([3,4,5,6,7,8]))

# Define the base period and filter for the growing season
base_period = growing_season_rad.sel(time=slice('1981-01-01', '2020-12-31'))

# Calculate the climatology (mean) and standard deviation for the base period for each pentad
rad_climatology = base_period['surface_net_solar_radiation_sum'].mean(dim='time')
#et_std = base_period['evaporation_from_vegetation_transpiration_sum'].std(dim='time')
# Calculate the standardized temperature anomalies for the entire dataset based on pentads
rad_anomalies = (growing_season_rad['surface_net_solar_radiation_sum'] - rad_climatology)
rad_anomalies = rad_anomalies.compute()
rad_anomalies.to_netcdf(output_folder + 'rad_anomalies.nc')
rad_anomalies = xr.open_dataset(output_folder + 'rad_anomalies.nc')
rad_anomalies['surface_net_solar_radiation_sum'].isel(time=1).plot(y='lat')

# calculate annual mean radiation anomaly
rad_anomalies = rad_anomalies.groupby('time.year').mean()
rad_anomalies = rad_anomalies.mean(dim=['year'])
rad_anomalies = rad_anomalies.where(foc_dataset['FOC'] >= 1, drop = True)

bounds = [-60000, -40000, -20000, 0, 20000, 40000, 60000]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
rad_anomalies['surface_net_solar_radiation_sum'].plot(
    ax=ax,
    y='lat',
    transform=ccrs.PlateCarree(),
    cmap='jet',
    norm=norm,
    add_colorbar=False  # Disable the automatic colorbar
)
# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Radiation Anomaly (j/m^2)', fontsize=16)  # Increase label size

#Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/rad_anomaly.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

"""### Computing average number of pentads under FD per growing season to be used for an extended season
#### Step 1: group by growing season
#### Step 2: assign the growing year
"""

# Create a new 'growing season year' coordinate
def growing_season_year(ds):
    # get time index
    time_index = ds.indexes['time']
    # Define the gr year: If month >= 9, it belongs to the next year
    gr_year = pd.Series(time_index.year, index=time_index)
    gr_year[time_index.month >= 9] += 1
    return gr_year

# Assign the gr year
flash_droughts_computed = flash_droughts_computed.assign_coords(growing_year=('time', growing_season_year(flash_droughts_computed)))


# Sum the flash drought conditions over the spatial dimensions and then group by growing season year
flash_droughts_per_season = flash_droughts_computed['flash_drought_condition'].sum(dim=['lon', 'lat']).groupby('growing_year').sum()

# Calculate the average number of pentads under flash drought per growing season year
num_lon_lat = flash_droughts_computed.dims['lon'] * flash_droughts_computed.dims['lat']
flash_droughts_per_season_avg = flash_droughts_per_season / num_lon_lat

# Plot the time series
plt.figure(figsize=(10, 6))
flash_droughts_per_season_avg.plot(marker='o')
plt.title('Average Number of Pentads under Flash Drought per Growing Season Year')
plt.xlabel('Growing Season Year')
plt.ylabel('Number of Pentads')
plt.grid(True)
plt.show()

"""### Computing average number of pentads under FD per growing season and trends of flash drought"""

flash_droughts_per_season = flash_droughts_computed_eastn['flash_drought_condition'].sum(dim=['lon', 'lat']).groupby('time.year').sum()

# Calculate the average number of pentads under flash drought per growing season year
num_lon_lat = flash_droughts_computed_eastn.dims['lon'] * flash_droughts_computed_eastn.dims['lat']
flash_droughts_per_season_avg = flash_droughts_per_season / num_lon_lat

# Convert to a pandas DataFrame for easier handling
flash_droughts_per_season_avg_df = flash_droughts_per_season_avg.to_dataframe()

# Extract years and pentads
years = flash_droughts_per_season_avg_df.index.values
pentads = flash_droughts_per_season_avg_df['flash_drought_condition'].values

# Perform the Mann-Kendall test
mk_result = mk.original_test(pentads)
slope = mk_result.slope
intercept = np.median(pentads) - slope * np.median(years)  # Estimate intercept for the trend line
trend_line = slope * years + intercept

# Plot the time series with the trend line
plt.figure(figsize=(10, 6))
plt.plot(years, pentads, marker='o', label='Average Number of Pentads')
plt.plot(years, trend_line, color='red', linestyle='--', label=f'Trend Line (p={mk_result.p:.3e})')
#plt.title('Average Number of Pentads under Flash Drought per Growing Season Year', fontsize=16)
plt.xlabel('Growing Season Year', fontsize=20)
plt.ylabel('Number of Pentads', fontsize=20)
plt.grid(True)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.legend(fontsize=20)

output_file_path = '/content/drive/MyDrive/Thesis/Average_grow_east.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""### Computing total pentads with FD"""

flash_drought_count = flash_drought_count.where(flash_drought_count.lat <= 15, drop=True)

bounds = [0,50, 100,150, 200, 250]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)
# Plot the total number of pentads with flash droughts
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
flash_drought_count.plot(ax=ax, y= 'lat', transform=ccrs.PlateCarree(), cmap='jet', norm=norm, add_colorbar=False)
# Plot the FOC with cartopy and discrete colors

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Total pentads with flash droughts', fontsize=16)  # Increase label size

#Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/total_pentad_east.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Set title
#plt.title('Total Number of Pentads with Flash Droughts')

# Show the plot
plt.show()

"""### Computing annual average pentad"""

# Sum the flash drought conditions over the time dimension grouped by growing season year
growing_season_flash_droughts = flash_droughts_computed_eastn['flash_drought_condition'].groupby('time.year').sum(dim='time')

# Calculate the average number of pentads under flash drought for each growing season year
growing_season_average_pentads = growing_season_flash_droughts.mean(dim='year')

# Plot the average number of pentads under flash drought for each growing season year
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
growing_season_average_pentads.plot(ax=ax,y= 'lat', transform=ccrs.PlateCarree(), cmap='viridis', cbar_kwargs={'label': 'Average Pentads with Flash Droughts per Growing Season Year'})

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 12, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 12, 'color': 'black'}  # Customize y-axis label style

#output_file_path = '/content/drive/MyDrive/Thesis/Average_pentad_east.tif'
#plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Set title
#plt.title('Average Number of Pentads with Flash Droughts per Growing Season Year')

# Show the plot
plt.show()

"""# Trend attribution
## examine the trend in the average number of flash drought per year
## examine the relationship between trend in the avergae number of flash drought per year and the variables
"""

# Perform the Mann-Kendall test
result = mk.original_test(flash_droughts_per_season_avg)
print(result)

#compute the mean soil moisture per year
soil_growing_season = ds['volumetric_soil_water_layer_1'].sel(time=ds['time.month'].isin([3, 4, 5, 6, 7, 8]))
soil_moisture_mean = soil_growing_season.sum(dim=['lon', 'lat']).groupby('time.year').sum()
computed_soil_moisture_mean_ea = soil_moisture_mean.compute()

#compute the mean temperature per year
temperature_growing_season = ds['temperature_2m'].sel(time=ds['time.month'].isin([3, 4, 5, 6, 7, 8]))
temperature_mean = temperature_growing_season.sum(dim=['lon', 'lat']).groupby('time.year').sum()
computed_temperature_mean_ea = temperature_mean.compute()

evaporation_growing_season = ds['evaporation_from_vegetation_transpiration_sum'].sel(time=ds['time.month'].isin([3, 4, 5, 6, 7, 8]))
evaporation_mean = evaporation_growing_season.sum(dim=['lon', 'lat']).groupby('time.year').sum()
computed_evaporation_mean_ea = evaporation_mean.compute()

computed_soil_moisture_mean_ea.to_netcdf(output_folder + 'computed_soil_moisture_mean_ea.nc')
computed_temperature_mean_ea.to_netcdf(output_folder + 'computed_temperature_mean_ea.nc')
computed_evaporation_mean_ea.to_netcdf(output_folder + 'computed_evaporation_mean_ea.nc')

computed_soil_moisture_mean_ea =xr.open_dataset(output_folder + 'computed_soil_moisture_mean_ea.nc')
computed_temperature_mean_ea =xr.open_dataset(output_folder + 'computed_temperature_mean_ea.nc')
computed_evaporation_mean_ea = xr.open_dataset(output_folder + 'computed_evaporation_mean_ea.nc')

#compute the relationship between the dependent and independent variable
res = stats.kendalltau(flash_droughts_per_season_avg, computed_temperature_mean_ea)

"""#Drivers of FD
### Linear regression analysis
"""

# Create a DataFrame
data = pd.DataFrame({
    'Flash_Droughts': flash_droughts_per_season_avg,
    'Soil_Moisture': computed_soil_moisture_mean_ea['volumetric_soil_water_layer_1'],
    'Temperature': computed_temperature_mean_ea['temperature_2m'],
    'Evaporation': computed_evaporation_mean_ea['evaporation_from_vegetation_transpiration_sum']
})

# Add a constant term for the intercept
X = data[['Soil_Moisture', 'Temperature', 'Evaporation']]
X = sm.add_constant(X)

# Dependent variable
y = data['Flash_Droughts']

# Perform the regression
model = sm.OLS(y, X).fit()

# Print the summary of the regression
print(model.summary())

# Get the coefficients
coefficients = model.params
print("\nCoefficients:\n", coefficients)

# Calculate the contributions
contributions = coefficients * X.mean()
print("\nContributions:\n", contributions)

# Proportion of each variable's contribution to flash droughts
proportions = contributions / contributions.sum()
print("\nProportions:\n", proportions)

report_path = output_folder + 'regression_report.txt'
with open(report_path, 'w') as f:
    f.write(str(model.summary()))
    f.write("\n\nCoefficients:\n")
    f.write(coefficients.to_string())
    f.write("\n\nContributions:\n")
    f.write(contributions.to_string())
    f.write("\n\nProportions:\n")
    f.write(proportions.to_string())

print(f"Report saved to {report_path}")

"""## FOC and Land Cover analysis"""

land_cover = (ee.ImageCollection('ESA/WorldCover/v200')
                .filter(ee.Filter.date('1980-01-01', '2023-12-31'))
                .filter(ee.Filter.bounds(roi)))

ds_landcover = xr.open_dataset(land_cover, engine='ee',
                         chunks={},
                         crs='EPSG:4326',
                         geometry=roi,
                         scale=0.1)
ds_landcover.plot()

# Align datasets on spatial and temporal dimensions
foc_dataset_aligned, ds_landcover_aligned = xr.align(foc_dataset, ds_landcover, join='inner')

masked_landcover = ds_landcover_aligned['Map'].where((ds_landcover_aligned['Map'] != 70) & (ds_landcover_aligned['Map'] != 80) &
 (ds_landcover_aligned['Map'] != 50))

# Aligning the masked landcover with foc_dataset
foc_dataset_aligned['masked_landcover_value'] = masked_landcover

# Now foc_dataset_aligned contains the landcover values for each grid cell
print(foc_dataset_aligned)

df = foc_dataset_aligned[['FOC', 'masked_landcover_value']].to_dataframe().dropna()

landcover_mapping = {
    10: 'Tree cover',
    20: 'Shrubland',
    30: 'Grassland',
    40: 'Cropland',
    50: 'Built-up',
    60: 'Bare/sparse vegetation',
    70: 'Snow and ice',
    80: 'Permanent water bodies',
    90: 'Herbaceous wetland',
    100: 'Moss and lichen'
}

# Replace numerical values with descriptive labels
df['masked_landcover_value'] = df['masked_landcover_value'].map(landcover_mapping)
df = df[df['FOC'] >= 1]

# Define a custom color palette
custom_palette = {
    'Tree cover': '#006400',
    'Shrubland': '#ff7f0e',
    'Grassland': '#2ca02c',
    'Cropland': '#f096ff',
    'Built-up': '#9467bd',
    'Bare/sparse vegetation': '#8c564b',
    'Snow and ice': '#e377c2',
    'Permanent water bodies': '#7f7f7f',
    'Herbaceous wetland': '#0096a0',
    'Moss and lichen': '#aec7e8'
    }

# Plot using seaborn
plt.figure(figsize=(14, 8))
sns.boxplot(x='masked_landcover_value', y='FOC', data=df, palette=custom_palette)
plt.xlabel('Landcover Type', fontsize=14)
plt.ylabel('FOC', fontsize=14)
#plt.title('Spatial pattern of flash drought')
plt.xticks(rotation=45)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Set y-axis limits to cover the extent of the data
#plt.ylim(df['FOC'].min(), df['FOC'].max())

# Add grid
plt.grid(axis='y')

output_file_path = '/content/drive/MyDrive/Thesis/flash_drought_pattern_east.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""##Map showing different land cover distribution within the **foc**"""

# Filter the landcover data based on the FOC values
land = masked_landcover.where(foc_dataset['FOC'] >= 1)

# Define the bounds and create the normalization for the colormap
bounds = [10, 20, 30, 40, 50, 60, 90, 100]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Define the labels for each bound
labels = ['Tree cover', 'Tree cover', 'Shrubland', 'Grassland', 'Cropland', 'Bare/sparse Vegetation', 'Herbaceous Wetland', 'Herbaceous Wetland']

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
land.plot(ax=ax, y='lat', transform=ccrs.PlateCarree(), cmap='jet',
          norm=norm, cbar_kwargs={'label': 'Landcover', 'boundaries': bounds, 'ticks': bounds})

# Add country boundaries and coastlines
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

# Customize the gridline label styles
gl.xlabel_style = {'size': 12, 'color': 'black'}
gl.ylabel_style = {'size': 12, 'color': 'black'}

# Update colorbar ticks with custom labels
cbar = ax.collections[0].colorbar
cbar.ax.set_yticklabels(labels)

# Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/land cover.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

plt.show()

"""#Ecosystem response to flash drought in the growing season
## identify flash drought at octad resolution
## calculate standardized GPP anomalies for the selected region
## masked the boundary of gpp anomalies and flash drought to the boundary of landcover with only vegetation
## add the masked gpp anomalies to the masked flash drought
## select masked flash drought that have negative gpp values
#calculate coincidence rate as the ratio of the number of flash drought events with negative GPPSA to the total number of flash drought events during the study period.

# Identify flash drought at Octad resolution
"""

# Assuming ds is your original dataset
# Let's first separate the first year from the rest of the dataset
first_year = ds.sel(time=str(ds.time.dt.year[0].values))
rest_of_years = ds.sel(time=slice(str(ds.time.dt.year[0].values + 1), None))

# Resample the first year starting from the first day
first_year_resampled = first_year.resample(time='8D').mean()

# Define a custom function to adjust the start day for the rest of the years
def resample_starting_from_day_6(ds):
    start_day_6 = ds.time.dt.dayofyear >= 1
    resampled_ds = ds.where(start_day_6, drop=True).resample(time='8D').mean()
    return resampled_ds

# Apply the custom resampling function to each year in the rest_of_years dataset
years = np.unique(rest_of_years.time.dt.year)
rest_of_years_resampled = []
for year in years:
    year_data = rest_of_years.sel(time=str(year))
    resampled_data = resample_starting_from_day_6(year_data)
    rest_of_years_resampled.append(resampled_data)

# Concatenate the first year and the rest of the years
rest_of_years_resampled = xr.concat(rest_of_years_resampled, dim='time')
resampled_ds = xr.concat([first_year_resampled, rest_of_years_resampled], dim='time')

print(resampled_ds)

#for time_coord in resampled_ds.isel(time=slice(0, 260)).time:
    #print(time_coord.values)
growing_season_octads = resampled_ds.sel(time=resampled_ds['time.month'].isin([3, 4, 5, 6, 7, 8]))
#for time_coord in growing_season_octads.isel(time=slice(0, 260)).time:
    #print(time_coord.values)


base_period = growing_season_octads.sel(time=slice('1981-01-01', '2020-12-31'))
temperature_climatology = base_period['temperature_2m'].mean(dim='time')
temperature_std = base_period['temperature_2m'].std(dim='time')

# Calculate the standardized temperature anomalies for the entire dataset based on pentads
temperature_anomalies = (growing_season_octads['temperature_2m'] - temperature_climatology) / temperature_std

# Calculate the climatology (mean) for ET during the base period for each pentad
et_climatology = base_period['evaporation_from_vegetation_transpiration_sum'].mean(dim='time')

# Calculate the ET anomalies based on the base period
et_anomalies = growing_season_octads['evaporation_from_vegetation_transpiration_sum'] - et_climatology

# Calculate the 40th percentile for soil moisture over the entire growing season period
!pip install bottleneck
# Rank the data along the time dimension
import bottleneck as bn # Import the missing module
# get sm
sm_octad = growing_season_octads['volumetric_soil_water_layer_1'].chunk({'time': -1})
# Rank the data along the time dimension
ranked_octad = sm_octad.compute().rank(dim='time')
ranked_octad.to_netcdf(output_folder + 'ranked_octad.nc')
# Normalise the ranks to get percentiles
percentiles = (ranked_octad / ranked_octad.max(dim='time'))*100
# Add the percentiles back to the dataset
growing_season_octads['soil_moisture_percentiles'] = percentiles

# Condition (a): Standardized Tair anomaly is greater than 1
condition_a = temperature_anomalies > 1

# Condition (b): ET anomaly is greater than 0
# !!! (note here negative values: evaporation should be higher than normal, which would correspond to more negative values of evaporation_from_vegetation_transpiration_sum )
condition_b = et_anomalies > 0

# Condition (c): SM is less than the 40th percentile
condition_c = growing_season_octads['soil_moisture_percentiles']< 40

# Combine conditions to identify pentads that meet all criteria
flash_drought_condition = condition_a & condition_b & condition_c

# Create a new DataArray to store the results
flash_droughts_octad = xr.Dataset({
    'temperature_anomalies': temperature_anomalies,
    'et_anomalies': et_anomalies,
    'sm_40th_percentile': condition_c,
    'flash_drought_condition': flash_drought_condition
})

flash_droughts_computed_octad_eastn = flash_droughts_octad.compute()

flash_droughts_computed_octad_eastn.to_netcdf(output_folder + 'flash_droughts_computed_octad_eastn.nc')
flash_droughts_computed_octad_eastn = xr.open_dataset(output_folder + 'flash_droughts_computed_octad_eastn.nc')

"""## compute standardised GPP anomalies"""

#from xclim.indices import dryness_index
#dryi = dryness_index(pr_dataset, evspsblpot_dataset, wo="200 mm")



vegetation_indices = ["GPP"]

gpp_dataset = (ee.ImageCollection("CAS/IGSNRR/PML/V2_v017")
                .filter(ee.Filter.date('1980-01-01', '2023-12-31'))
                .filter(ee.Filter.bounds(roi))
                .select(vegetation_indices))
ds_gpp = xr.open_dataset(gpp_dataset, engine='ee',
                         chunks={},
                         crs='EPSG:4326',
                         geometry=roi,
                         scale=0.1)
ds_gpp['GPP'].isel(time =1).plot(y='lat')
season = [3, 4, 5, 6, 7, 8]
growing_season_gpp = ds_gpp.sel(time=ds_gpp.time.dt.month.isin(season))

# Calculate the climatology (mean) and standard deviation for the entire study period
gpp_climatology = growing_season_gpp.mean(dim='time')
gpp_std = growing_season_gpp.std(dim='time')

# Calculate the standardized gpp anomalies for the entire dataset based on pentads
gpp_anomalies = (growing_season_gpp['GPP'] - gpp_climatology) / gpp_std
computed_gpp_anomalies= gpp_anomalies.compute()

# remove the irrelevant landcover class
masked_landcover = ds_landcover['Map'].where((ds_landcover['Map'] != 70) & (ds_landcover['Map'] != 80) & (ds_landcover['Map'] != 50))

#Function to apply the mask to each time step
def apply_mask_to_timestep(gpp_anomalies_timestep, masked_landcover):
    masked_landcover_aligned = masked_landcover.reindex_like(gpp_anomalies_timestep, method='nearest')
    masked_gpp = gpp_anomalies_timestep.where(masked_landcover_aligned.notnull())
    return masked_gpp

# mask the boundary of the GPP anomlaies with the landcover boundary
masked_gpp_anomalies_list = []
for t in computed_gpp_anomalies.time:
    gpp_anomalies_timestep = computed_gpp_anomalies.sel(time=t)
    masked_gpp_anomalies_timestep = apply_mask_to_timestep(gpp_anomalies_timestep, masked_landcover)
    masked_gpp_anomalies_list.append(masked_gpp_anomalies_timestep)

# Concatenate the results along the time dimension
masked_gpp_anomalies = xr.concat(masked_gpp_anomalies_list, dim='time')

# Ensure the time coordinates are the same as in the original dataset
masked_gpp_anomalies['time'] = computed_gpp_anomalies['time']

# slice the flash drought dataset from 2000-2020
flash_droughts_computed_filtered = flash_droughts_computed_octad_eastn['flash_drought_condition'].sel(time=slice('2000', '2020'))

# masked the flash drought boundary with the landcover
masked_flash_droughts_computed_list = []
for t in flash_droughts_computed_filtered.time:
    flash_droughts_computed_filtered_timestep = flash_droughts_computed_filtered.sel(time=t)
    masked_flash_droughts_computed_timestep = apply_mask_to_timestep(flash_droughts_computed_filtered_timestep, masked_landcover)
    masked_flash_droughts_computed_list.append(masked_flash_droughts_computed_timestep)

# Concatenate the results along the time dimension
masked_flash_droughts_computed = xr.concat(masked_flash_droughts_computed_list, dim='time')

# Ensure the time coordinates are the same as in the original dataset
masked_flash_droughts_computed['time'] = flash_droughts_computed_filtered['time']

#align the dataset
masked_flash_droughts_computed_aligned, masked_gpp_anomalies_aligned = xr.align(masked_flash_droughts_computed,
                                masked_gpp_anomalies['GPP'], join='inner')


# Add the masked the gpp values to flash drought
masked_flash_droughts_computed_aligned['masked_gpp_value'] = masked_gpp_anomalies_aligned

# Select entries where the GPP values are negative
negative_gpp_mask = masked_gpp_anomalies_aligned < 0
negative_gpp_mask_computed = negative_gpp_mask.compute()

# use the computed mask for indexing
selected_flash_droughts = masked_flash_droughts_computed_aligned.where(negative_gpp_mask_computed, drop=True)

# Ensure the time coordinates are correctly managed
selected_flash_droughts['time'] = masked_flash_droughts_computed_aligned['time']

flash_drought_gpp = selected_flash_droughts.compute()

# Count the occurrences of flash droughts with negative gpp (True values) along the time dimension
flash_drought_gpp_count = flash_drought_gpp.sum(dim='time')

total_pentads = masked_flash_droughts_computed_aligned.sizes['time']

# Calculate the coincidence rate as the number of FD pentads with negative GPP divided by total pentads  with FD
cr = (flash_drought_gpp_count / total_pentads)
cr_dataset = xr.Dataset({'cr': cr})

"""## Calculate the FOC of the 8days aggregrated flash droughts"""

# Calculate the total number of pentads (time steps)
total_pentads_octad = masked_flash_droughts_computed.sizes['time']
masked_flash_droughts_computed =masked_flash_droughts_computed.compute()
# Count the occurrences of flash droughts (True values) along the time dimension
flash_drought_count = masked_flash_droughts_computed.sum(dim='time')

foc_octad = (flash_drought_count / total_pentads) * 100

# Convert the result to a Dataset for easier handling and visualization
foc_dataset_octad = xr.Dataset({'FOC': foc_octad})

# Define the discrete color boundaries, adjusted for the FOC range
bounds = [0,1, 2,3,4, 5]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(12, 6), subplot_kw={'projection': ccrs.PlateCarree()})
foc_dataset_octad['FOC'].plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        norm=norm, cbar_kwargs={'label': 'FOC', 'boundaries': bounds, 'ticks': bounds})

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 12, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 12, 'color': 'black'}  # Customize y-axis label style

# Set title
#plt.title('Frequency of occurence')
# Save the plot to a file
#output_file_path = '/content/drive/MyDrive/Thesis/foc_octad_east.jpg'
#plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

"""## Distribution of Coincidence rate across the mean annual temperature and precipitation"""

select = ds['temperature_2m'].sel(time=slice('2000', '2020'))
select = select.sel(time=select.time.dt.month.isin(season))

mat = select.groupby('time.year').mean()
mmat20m = mat.mean(dim=['year'])
mmat20m.to_netcdf(output_folder + 'mmat20m.nc')
mmat20m = xr.open_dataset(output_folder + 'mmat20m.nc')
mmat20m['temperature_2m'].plot(y='lat')

selectp = ds_prep['total_precipitation_sum'].sel(time=slice('2000', '2020'))
selectp = selectp.sel(time=selectp.time.dt.month.isin(season))
pre = selectp.groupby('time.year').mean()
prep20m = pre.mean(dim=['year'])
prep20m.to_netcdf(output_folder + 'prep20m.nc')
prep20m = xr.open_dataset(output_folder + 'prep20m.nc')

cr = cr_dataset['cr'].where(cr_dataset['cr'] >= 0.01)

#Flatten the data for plotting
mmat_array = mmat20m['temperature_2m']
prep_array = prep20m['total_precipitation_sum']


mat_flat = mmat_array.values.flatten()
prep_flat = prep_array.values.flatten()
cr_flat = cr.values.flatten()

# Create a DataFrame for easier manipulation and plotting
import pandas as pd

data = pd.DataFrame({
    'MAT': mat_flat,
    'PREP': prep_flat,
    'CR': cr_flat
})

# Filter out invalid data points (e.g., NaN values)
data = data.dropna()

# Plot the distribution of FOC characteristics in the climate space
plt.figure(figsize=(12, 8))
scatter = plt.scatter(data['PREP'], data['MAT'], c=data['CR'], cmap='viridis', alpha=0.5)
plt.colorbar(scatter, label='Coincidence rate')
#cbar = plt.colorbar(scatter, label='Coincidence rate')
#cbar.set_ticks([0,0.01,0.02, 0.04,0.06,0.08, 0.1])  # Set the ticks for the colorbar
#cbar.set_ticklabels([0,0.01,0.02, 0.04,0.06,0.08, 0.1])


plt.xlabel('Mean Annual Precipitation (m)', fontsize = 14)

plt.ylabel('Mean Annual Temperature (K)', fontsize = 14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
#plt.title('Distribution of FOC Characteristics in Climate Space')
output_file_path = '/content/drive/MyDrive/Thesis/climatic_dist_cr.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

plt.show()

sets = mmat20m['temperature_2m'].where(foc_dataset_octad['FOC'] >= 1, drop = True)
#selectp.plot()
#bounds = [0,0.01,0.02,0.03, 0.04, 0.05 ]
bounds = [280, 285, 290,295,300,305,310,315,320]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
sets.plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        norm=norm, cbar_kwargs={'label': 'FOC', 'boundaries': bounds, 'ticks': bounds})
# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 12, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 12, 'color': 'black'}  # Customize y-axis label style

# Set title
#plt.title('Frequency of occurence')
# Save the plot to a file
#output_file_path = '/content/drive/MyDrive/Thesis/foc_octad_east.jpg'
#plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

setp = prep20m['total_precipitation_sum'].where(foc_dataset_octad['FOC'] >= 1)
bounds = [0,0.001, 0.002, 0.003, 0.004,0.005,0.006,0.007,0.008,0.009,0.01]
#bounds = [280, 285, 290,295,300,305,310,315,320]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
setp.plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        norm=norm, cbar_kwargs={'label': 'FOC', 'boundaries': bounds, 'ticks': bounds})
# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 12, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 12, 'color': 'black'}  # Customize y-axis label style

# Set title
#plt.title('Frequency of occurence')
# Save the plot to a file
#output_file_path = '/content/drive/MyDrive/Thesis/foc_octad_east.jpg'
#plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

"""## Map showing th coincidence map"""

# Define the discrete color boundaries, adjusted for the FOC range
bounds = [0.01,0.02, 0.04,0.06,0.08, 0.09,0.1]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
cr_dataset['cr'].plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        norm=norm, cbar_kwargs={'label': 'Coincidence rate', 'boundaries': bounds, 'ticks': bounds})

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 12, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 12, 'color': 'black'}  # Customize y-axis label style

# Set title
#plt.title('Coincidence Rate')
# Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/CR_east.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

"""#spatial distribution of mean gpp anomalies during flash drought event
## calculate the mean of the gpp anomalies across the tine step
##mask the mean gpp anomalies with the boundary of foc greater than 1 to remove the areas with no flash drought events.
"""

mean_gpp = masked_gpp_anomalies['GPP'].mean(dim=['time'])
# Now create the Dataset
meangpp_dataset_octad = xr.Dataset({'GPP': mean_gpp})
masked_mean_gpp = meangpp_dataset_octad.where(foc_dataset_octad['FOC'] >= 1)

bounds = [ -1,-0.5, 0, 0.5 ]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
masked_mean_gpp['GPP'].plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        norm=norm, cbar_kwargs={'label': 'FOC', 'boundaries': bounds, 'ticks': bounds})
# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False

gl.xlabel_style = {'size': 12, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 12, 'color': 'black'}  # Customize y-axis label style

# Set title
#plt.title('Frequency of occurence')
# Save the plot to a file
#output_file_path = '/content/drive/MyDrive/Thesis/foc_octad_east.jpg'
#plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

"""## Spatial distribution of gpp anomalies across the vegetation type
## mask out the area in the landcover with built-up, water,and area with foc less than 1 to remove the area withought flash drought
##align the mean gpp anomalies of where flash drought occur with the masked landcover
## plot the mean gppp anomalies against the landcover type to visualise the response of photosynthesis to flash drought

"""

masked_landcover = ds_landcover['Map'].where((ds_landcover['Map'] != 70) & (ds_landcover['Map'] != 80) & (ds_landcover['Map'] != 50))

masked_landcover = masked_landcover.where(foc_dataset_octad['FOC'] >= 1)

masked_mean_gpp_aligned, ds_landcover_aligned = xr.align(masked_mean_gpp, masked_landcover, join='inner')

# Aligning the masked landcover with foc_dataset
masked_mean_gpp_aligned['masked_landcover_value'] = masked_landcover

# Now foc_dataset_aligned contains the landcover values for each grid cell
print(masked_mean_gpp_aligned)

df = masked_mean_gpp_aligned[['GPP', 'masked_landcover_value']].to_dataframe().dropna()

landcover_mapping = {
    10: 'Tree cover',
    20: 'Shrubland',
    30: 'Grassland',
    40: 'Cropland',
    50: 'Built-up',
    60: 'Bare/sparse vegetation',
    70: 'Snow and ice',
    80: 'Permanent water bodies',
    90: 'Herbaceous wetland',
    100: 'Moss and lichen'
    }

  # Define a custom color palette
custom_palette = {
    'Tree cover': '#006400',
    'Shrubland': '#ff7f0e',
    'Grassland': '#2ca02c',
    'Cropland': '#f096ff',
    'Built-up': '#9467bd',
    'Bare/sparse vegetation': '#8c564b',
    'Snow and ice': '#e377c2',
    'Permanent water bodies': '#7f7f7f',
    'Herbaceous wetland': '#0096a0',
    'Moss and lichen': '#aec7e8'
    }

# 5. Replace numerical values with descriptive labels
df['masked_landcover_value'] = df['masked_landcover_value'].map(landcover_mapping)
#df = df[df['FOC'] >= 1]

# 6. Plot using seaborn
plt.figure(figsize=(14, 8))
sns.boxplot(x='masked_landcover_value', y='GPP', data=df, palette=custom_palette)
plt.xlabel('Landcover Type', fontsize=14)
plt.ylabel('GPP', fontsize=14)
#plt.title('Spatial pattern of flash drought')
plt.xticks(rotation=45)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(axis='y')
output_file_path = '/content/drive/MyDrive/Thesis/gpp_pattern_east.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""# Analysis of coincidate rate and land Cover
## Align the cr with the masked landcover
## covert the two to a dataframe
## remove the area with cr less than 0.01 i.e where flash drought does not occur
"""

# Align datasets on spatial and temporal dimensions
cr_dataset_aligned, masked_landcover_aligned = xr.align(cr_dataset, masked_landcover, join='inner')

# adding the aligned masked land cover values to cr
cr_dataset_aligned['masked_landcover_value'] = masked_landcover_aligned

df = cr_dataset_aligned[['cr', 'masked_landcover_value']].to_dataframe().dropna()
df = df[df['cr'] > 0.01]

landcover_mapping = {
    10: 'Tree cover',
    20: 'Shrubland',
    30: 'Grassland',
    40: 'Cropland',
    50: 'Built-up',
    60: 'Bare/sparse vegetation',
    70: 'Snow and ice',
    80: 'Permanent water bodies',
    90: 'Herbaceous wetland',
    100: 'Moss and lichen'
    }
# Define a custom color palette
custom_palette = {
    'Tree cover': '#006400',
    'Shrubland': '#ff7f0e',
    'Grassland': '#2ca02c',
    'Cropland': '#f096ff',
    'Built-up': '#9467bd',
    'Bare/sparse vegetation': '#8c564b',
    'Snow and ice': '#e377c2',
    'Permanent water bodies': '#7f7f7f',
    'Herbaceous wetland': '#0096a0',
    'Moss and lichen': '#aec7e8'
    }

# 5. Replace numerical values with descriptive labels
df['masked_landcover_value'] = df['masked_landcover_value'].map(landcover_mapping)

# 6. Plot using seaborn
plt.figure(figsize=(14, 8))
sns.boxplot(x='masked_landcover_value', y='cr', data=df, palette=custom_palette)
plt.xlabel('Landcover Type', fontsize =26)
plt.ylabel('Coincidence rate', fontsize =26)
#plt.title('Spatial patterns of coincidence rate')
plt.xticks(rotation=20)

plt.xticks(fontsize=26)
plt.yticks(fontsize=26)
plt.grid(axis='y')

output_file_path = '/content/drive/MyDrive/Thesis/spatial_CR_east.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""# identify flash drought using root zone soil moisture
## conditions
The pentad mean RZSM decreases from above 40th percentile to below 20th percentile, with an average decline rate of no less than 5% in RZSM percentiles for each pentad.

The FD is considered to have terminated if the declined RZSM rises to 20th percentile again. These two criteria determine the onset and termination stages of an FD event.

The drought should last for at least 3 pentads (15 days).

## The approach above follows: [KMukherjee and Mishra 2022 ]   https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021GL096804
"""

soil_layers = ["volumetric_soil_water_layer_1", "volumetric_soil_water_layer_2", "volumetric_soil_water_layer_3"]
soil_dataset = (ee.ImageCollection("ECMWF/ERA5_LAND/DAILY_AGGR")
                .filter(ee.Filter.date('1980-01-01', '2023-12-31'))
                .filter(ee.Filter.bounds(roi))
                .select(soil_layers))

ds_soil_layer = xr.open_dataset(soil_dataset, engine='ee',
                         chunks={},
                         crs='EPSG:4326',
                         geometry=roi,
                         scale=0.1)
ds_soil_layer['volumetric_soil_water_layer_1'].isel(time =200).plot(y='lat')

"""## compute the root zone soil moisture"""

depth1 = 7    # depth of layer 1 (0-7 cm)
depth2 = 21   # depth of layer 2 (7-28 cm)
depth3 = 2    # depth of layer 3 (28-30 cm, only top 2 cm considered)

# Calculate the total depth of the top 30 cm
total_depth = depth1 + depth2 + depth3  # total_depth = 30 cm

# Calculate the weights for each layer as the proportion of the total depth
c1 = depth1 / total_depth  # c1 = 7 / 30 = 0.2333
c2 = depth2 / total_depth  # c2 = 21 / 30 = 0.7
c3 = depth3 / total_depth  # c3 = 2 / 30 = 0.0667

# Access the data for each layer
layer1 = ds_soil_layer['volumetric_soil_water_layer_1']  # Data for 0-7 cm layer
layer2 = ds_soil_layer['volumetric_soil_water_layer_2']  # Data for 7-28 cm layer
layer3 = ds_soil_layer['volumetric_soil_water_layer_3']  # Data for 28-100 cm layer

# Calculate the weighted mean soil moisture for the top 30 cm
rzsm = (
    (layer1 * c1) + (layer2 * c2) + (layer3 * c3)
)
rzsm_pentads = rzsm.resample(time='5D').mean()
# compute the rszm
computed_rszm = rzsm_pentads.compute()
computed_rszm.to_netcdf('computed_rszm.nc')
computed_rszm = xr.open_dataset(output_folder + 'computed_rszm (1).nc')
#rename variable
computed_rszm = computed_rszm.rename({'__xarray_dataarray_variable__': 'RZSM'})

# Define the time index you want to plot
time_index = 200

# Get the minimum and maximum values across all layers for consistent color scales
vmin = min(
    ds_soil_layer['volumetric_soil_water_layer_1'].isel(time=time_index).min().compute(),
    ds_soil_layer['volumetric_soil_water_layer_2'].isel(time=time_index).min().compute(),
    ds_soil_layer['volumetric_soil_water_layer_3'].isel(time=time_index).min().compute(),
    rzsm.isel(time=time_index).min().compute()
)

vmax = max(
    ds_soil_layer['volumetric_soil_water_layer_1'].isel(time=time_index).max().compute(),
    ds_soil_layer['volumetric_soil_water_layer_2'].isel(time=time_index).max().compute(),
    ds_soil_layer['volumetric_soil_water_layer_3'].isel(time=time_index).max().compute(),
    rzsm.isel(time=time_index).max().compute()
)

# Create a figure and set of subplots
fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))

# Plot each layer with the same color scale
ds_soil_layer['volumetric_soil_water_layer_1'].isel(time=time_index).plot(ax=axes[0], y='lat', vmin=vmin, vmax=vmax)
axes[0].set_title('Soil Water Layer 1 (0-7 cm)')

ds_soil_layer['volumetric_soil_water_layer_2'].isel(time=time_index).plot(ax=axes[1], y='lat', vmin=vmin, vmax=vmax)
axes[1].set_title('Soil Water Layer 2 (7-28 cm)')

ds_soil_layer['volumetric_soil_water_layer_3'].isel(time=time_index).plot(ax=axes[2], y='lat', vmin=vmin, vmax=vmax)
axes[2].set_title('Soil Water Layer 3 (28-100 cm)')

rzsm.isel(time=time_index).plot(ax=axes[3], y='lat', vmin=vmin, vmax=vmax)
axes[3].set_title('Depth Weighted Soil Moisture')

# Adjust layout for better spacing
plt.tight_layout()

# Show the plot
plt.show()

"""### compute percentile"""

# compute percentile
!pip install bottleneck
# Rank the data along the time dimension
import bottleneck as bn # Import the missing module
# get sm
rzsm = computed_rszm ['RZSM'].chunk({'time': -1})
# Rank the data along the time dimension
ranked = rzsm.compute().rank(dim='time')
# Normalize the ranks to get percentiles
percentiles = (ranked / ranked.max(dim='time'))*100
computed_rszm['RZSM_percentile'] = percentiles
computed_rszm.to_netcdf(output_folder + 'computed_rszmp.nc')
computed_rszmp = xr.open_dataset(output_folder + 'computed_rszmp.nc')
#computed_rszmp['RZSM_percentile'].isel(time=200).plot(y = 'lat')

"""## identfy FD based on rapid onset criteria"""

# Define the criteria for flash drought (FD)
rzsm_percentile = computed_rszmp['RZSM_percentile']
fd_onset = np.full(rzsm_percentile.shape, np.nan)  # Placeholder for FD onset
fd_termination = np.full(rzsm_percentile.shape, np.nan)  # Placeholder for FD termination

# Loop through each grid point (lon, lat)
for i in range(rzsm_percentile.shape[1]):  # lon
    for j in range(rzsm_percentile.shape[2]):  # lat
        # Extract time series for the current grid point
        series = rzsm_percentile[:, i, j].values

        potential_onset = None

        for t in range(4, len(series) - 3):  # Stop early to allow for checking next 3 pentads
            # Look for a potential onset
            if potential_onset is None:
                if series[t] <= 20:
                    for k in range(1, 5):  # Look back 4 pentads
                        if series[t-k] > 40:
                            potential_onset = t - k
                            break

            # Confirm the drought if it lasts for at least 3 pentads below the 20th percentile
            if potential_onset is not None:
                if series[t] <= 20 and series[t+1] <= 20 and series[t+2] <= 20:
                    fd_onset[potential_onset, i, j] = 1  # Mark the onset
                    # Mark termination at the first point where RZSM rises above 20% after the drought is confirmed
                    for t_term in range(t+3, len(series)):
                        if series[t_term] >= 20:
                            fd_termination[t_term, i, j] = 1
                            potential_onset = None  # Reset for the next event
                            break
                else:
                    potential_onset = None  # Reset if the criteria are not met

# Adding FD onset and termination to the dataset
computed_rszmp['FD_onset'] = (('time', 'lon', 'lat'), fd_onset)
computed_rszmp['FD_termination'] = (('time', 'lon', 'lat'), fd_termination)
#computed_rszmp.to_netcdf(output_folder + 'computed_rszmpd.nc')

# Calculate the count of FD events over the entire time period
computed_rszmp = computed_rszmp.sel(time=computed_rszmp['time.month'].isin([3,4,5,6,7,8]))
fd_count = computed_rszmp['FD_onset'].count(dim='time')
# Transpose the fd_count array to match the dimensions of lon and lat for plotting
fd_count = fd_count.T
total_pentads = computed_rszmp.dims['time']

# Calculate the Frequency of Occurrence (FOC) as a percentage
foc = (fd_count / total_pentads) * 100
# Convert the result to a Dataset for easier handling and visualization
foc_dataset = xr.Dataset({'FOC': foc})
foc_dataset = foc_dataset.where(foc_dataset.lat <= 15, drop=True)
#foc_dataset = foc_dataset.where(foc_dataset >= 0.1, drop=True)

#cr = cr_dataset['cr'].where(cr_dataset['cr'] >= 0.01)

bounds = [0, 0.5, 1, 1.5, 2, 2.5, 3]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)

# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
foc_dataset['FOC'].plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        add_colorbar=False)

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax, boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Frequency of occurrence (%)', fontsize=16)  # Increase label size

# Set title
#plt.title('Frequency of Occurrence (FOC) of Flash Droughts', fontsize=16)
#ax.figure.colorbar(ax.collections[0]).ax.tick_params(labelsize=14)

#Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/foc_growing_season_east_onset.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

#remove areas greater than latitude 10 degree
fd_count = fd_count.where(fd_count.lat <= 15, drop=True)

#visualise
bounds = [0, 10, 20, 30, 40, 50]
norm = BoundaryNorm(bounds, ncolors=256, clip=True)
# Plot the FOC with cartopy and discrete colors
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
fd_count.plot(ax=ax,y='lat', transform=ccrs.PlateCarree(), cmap='jet',
                        add_colorbar=False)

# Add country boundaries
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.COASTLINE)

# Add gridlines
gl = ax.gridlines(draw_labels=True)
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 16, 'color': 'black'}  # Customize x-axis label style
gl.ylabel_style = {'size': 16, 'color': 'black'}  # Customize y-axis label style

# Manually add the colorbar with customized ticks and labels
cbar = ax.figure.colorbar(ax.collections[0], ax=ax,  boundaries=bounds, ticks=bounds)
cbar.ax.tick_params(labelsize=16)  # Adjust tick label size
cbar.ax.set_ylabel('Total pentads with flash droughts', fontsize=16)  # Increase label size

# Set title
#plt.title('Frequency of Occurrence (FOC) of Flash Droughts', fontsize=16)
#ax.figure.colorbar(ax.collections[0]).ax.tick_params(labelsize=14)

#Save the plot to a file
output_file_path = '/content/drive/MyDrive/Thesis/total_pentads_onset.tif'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)

# Show the plot
plt.show()

# Define the specified latitude and longitude
latitude = 0
longitude = 30

start_date = '2022-01-31'
end_date = '2022-12-31'

# Extract the time series for the specified coordinate using 'nearest'
time_series = computed_rszmp['RZSM_percentile'].sel(lat=latitude, lon=longitude, method='nearest')
fd_onset_series = computed_rszmp['FD_onset'].sel(lat=latitude, lon=longitude, method='nearest')
fd_termination_series = computed_rszmp['FD_termination'].sel(lat=latitude, lon=longitude, method='nearest')

# Select the time period
time_series = time_series.sel(time=slice(start_date, end_date))
fd_onset_series = fd_onset_series.sel(time=slice(start_date, end_date))
fd_termination_series = fd_termination_series.sel(time=slice(start_date, end_date))

# Further filter to include only March to August in each year
time_series = time_series.sel(time=time_series.time.dt.month.isin([3, 4, 5, 6, 7, 8]))
fd_onset_series = fd_onset_series.sel(time=fd_onset_series.time.dt.month.isin([3, 4, 5, 6, 7, 8]))
fd_termination_series = fd_termination_series.sel(time=fd_termination_series.time.dt.month.isin([3, 4, 5, 6, 7, 8]))

# Extracting start and end of flash droughts
fd_periods = []
current_start = None

for t in range(len(time_series.time)):
    if fd_onset_series.isel(time=t) == 1:
        current_start = time_series.time[t].values
    if fd_termination_series.isel(time=t) == 1 and current_start is not None:
        fd_periods.append((current_start, time_series.time[t].values))
        current_start = None

plt.figure(figsize=(10, 8))

# Plot the RZSM time series with dots
plt.plot(time_series.time, time_series, label='RZSM Percentile', color='blue', marker='o')

# Highlight the flash drought events using filled regions
for start, end in fd_periods:
    plt.axvspan(start, end, color='orange', alpha=0.3, label='Flash Drought' if start == fd_periods[0][0] else "")

# Add horizontal lines for the 20th and 40th percentiles
plt.axhline(20, color='red', linestyle='--', label='20th Percentile')
plt.axhline(40, color='green', linestyle='--', label='40th Percentile')


#plt.title(f'RZSM Percentile Time Series at (lat={latitude}, lon={longitude}) from July to October 2010')
plt.xlabel('Time', fontsize =14)
plt.ylabel('RZSM Percentile', fontsize =14)

plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.grid(axis='x')
plt.legend(fontsize =14)
output_file_path = '/content/drive/MyDrive/Thesis/FD_stage.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()

"""## Average pentads under FD per year and trends"""

computed_rszmp['FD_onset']
computed_rszmp = computed_rszmp.sel(time=computed_rszmp['time.month'].isin([3,4,5,6,7,8]))

# Assuming flash_droughts_computed_sosu is already loaded as an xarray dataset
# flash_droughts_computed = xr.open_dataset(output_folder + 'flash_droughts_computed.nc')
flash_droughts_per_season = computed_rszmp['FD_onset'].sum(dim=['lon', 'lat']).groupby('time.year').sum()

# Calculate the average number of pentads under flash drought per growing season year
num_lon_lat = computed_rszmp.dims['lon'] * computed_rszmp.dims['lat']
flash_droughts_per_season_avg = flash_droughts_per_season / num_lon_lat

# Convert to a pandas DataFrame for easier handling
flash_droughts_per_season_avg_df = flash_droughts_per_season_avg.to_dataframe()

# Extract years and pentads
years = flash_droughts_per_season_avg_df.index.values
pentads = flash_droughts_per_season_avg_df['FD_onset'].values

# Perform the Mann-Kendall test
mk_result = mk.original_test(pentads)
slope = mk_result.slope
intercept = np.median(pentads) - slope * np.median(years)  # Estimate intercept for the trend line
trend_line = slope * years + intercept

# Plot the time series with the trend line
plt.figure(figsize=(10, 6))
plt.plot(years, pentads, marker='o', label='Average Number of Pentads')
plt.plot(years, trend_line, color='red', linestyle='--', label=f'Trend Line (p={mk_result.p:.3e})')
#plt.title('Average Number of Pentads under Flash Drought per Growing Season Year', fontsize=16)
plt.xlabel('Growing Season Year', fontsize=20)
plt.ylabel('Number of Pentads', fontsize=20)
plt.grid(True)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.legend()

output_file_path = '/content/drive/MyDrive/Thesis/Average_grow_east_onset.jpg'
plt.savefig(output_file_path, bbox_inches='tight', dpi=300)
plt.show()